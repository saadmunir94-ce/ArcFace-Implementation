
# ArcFace Implementation

This is my implementation of the research paper "ArcFace: Additive Angular Margin Loss for Deep Facial Recognition" on a subset of LFW dataset with 18 face categories. I have implemented the code in PyTorch framework.
Usually, a deep Convolutional Neural Network is trained with traditional softmax loss function. Intuitively, embeddings of the same face should be mapped close to each other and embeddings of different faces
should be more apart from each other. However, the softmax loss does not explicitly optimize the feature embeddings to enforce higher similarity for intra class samples and diversity for inter-class samples. Consequently, there could be a performance drop while generalizing the facial recognition system under large intra-class appearance variations (e.g. pose variations, age gaps). To counteract this, the authors propose a new geometrically interpretable loss function, called **Arcface**, that directly maximizes the decision boundary in angular space, effectively pulling features of the same class closer together and pushing features of different classes further apart. By incorporating the angular margin into the loss function, ArcFace aims to improve the robustness of face recognition systems to variations in illumination, pose, and expression.
My implementation compares the performance metrics on the validation set of my subset of LFW dataset using the traditional softmax loss and the ArcFace loss function. Evidently, the ArcFace generalizes better than the softmax loss function. Lastly, I have also visualized the feature embeddings in 2-D space using t-SNE for both the softmax and ArcFace losses. It could be observed that the faces of the same person are closer to each other and more separable from faces of the other people in the feature embeddings of the ArcFace than of the softmax.  We could conclude that ArcFace has learned **more discriminative features** than the softmax.
