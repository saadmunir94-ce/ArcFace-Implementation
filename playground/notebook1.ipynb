{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArcFace class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFace(nn.Module):\n",
    "    \"\"\"\n",
    "    ArcFace Layer for face recognition.\n",
    "    This layer is used for face recognition tasks. It computes the class logits using the ArcFace algorithm.\n",
    "\n",
    "    Attributes:\n",
    "        emb_size (int): The embedding size (the number of features extracted from CNN).\n",
    "        num_classes (int): The number of classes.\n",
    "        s (float): The radius of the projected hypersphere.\n",
    "        m (float): The arc margin in radians.\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_size, num_classes, s=64.0, m=0.50):\n",
    "        \"\"\"\n",
    "        Constructor for ArcFace Layer.\n",
    "\n",
    "        Parameters:\n",
    "            emb_size (int): The embedding size (the number of features extracted from CNN).\n",
    "            num_classes (int): The number of classes.\n",
    "            s (float): The radius of the projected hypersphere. Default is 64.0.\n",
    "            m (float): The arc margin in radians. Default is 0.50.\n",
    "        \"\"\"\n",
    "        # inherit from base class\n",
    "        super(ArcFace, self).__init__()\n",
    "        # save configuration\n",
    "        self.num_classes = num_classes\n",
    "        self.emb_size = emb_size\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        # formulate weight tensor\n",
    "        self.weights = Parameter(torch.FloatTensor(num_classes, emb_size))\n",
    "        # initialize weights\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def forward(self, embedding, gt):\n",
    "        \"\"\"\n",
    "        Computes the forward pass using the Arcface loss and returns the class logits.\n",
    "\n",
    "        Parameters:\n",
    "            embedding (torch.Tensor): Extracted embeddings.\n",
    "            gt (torch.Tensor): Ground truth labels.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Computed class logits through ArcFace Algorithm.\n",
    "        \"\"\"\n",
    "        print(f\"batch dim = {embedding.shape[0]}\")\n",
    "        print(f\"Embedding size = {self.emb_size}\")\n",
    "        print(f\"Shape of embedding {embedding.shape}\")\n",
    "        print(f\"No of classes = {self.num_classes}\")\n",
    "        print(f\"shape of weights {self.weights.shape}\")\n",
    "        \n",
    "        fc7 = F.linear(F.normalize(embedding, dim=1), F.normalize(self.weights, dim=1), bias=None)\n",
    "        print(f\"Shape of logits = {fc7.shape}\")\n",
    "        # pick logit at class index\n",
    "        one_hot = F.one_hot(gt, self.num_classes)\n",
    "        print(f\"One hot encoded labels are {one_hot}\")\n",
    "        print(f\"Logits of all classes {fc7}\")\n",
    "        original_target_logit = fc7[one_hot > 0]\n",
    "        print(f\"original target logit = {original_target_logit}\")\n",
    "        # theta\n",
    "        eps = 1e-10\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = torch.acos(torch.clamp(original_target_logit, -1.0 + eps, 1.0 - eps))\n",
    "        # marginal_target_logit\n",
    "        marginal_target_logit = torch.cos(theta + self.m)\n",
    "        \n",
    "        # update fc7\n",
    "        diff = marginal_target_logit - original_target_logit\n",
    "        print(f\"diff in raw form is {diff}\")\n",
    "        print(\"diff after unsqueezing is {}\".format(torch.unsqueeze(diff, dim=1)))\n",
    "        print(f\"fc7 originally is {fc7}\")\n",
    "        print(\"Multiplication of one hot encoding with diff: {}\".format(torch.mul(one_hot, torch.unsqueeze(diff, dim=1))))\n",
    "        fc7 = fc7 + torch.mul(one_hot, torch.unsqueeze(diff, dim=1))\n",
    "        print(f\"fc7 after inclusion of margin in the ground truth logits \\n: {fc7}\")\n",
    "        # scaling\n",
    "        fc7 *= self.s\n",
    "        return fc7\n",
    "        \n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Returns a deep copy of the weights which serve as class centroids.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Deep copy of the weights.\n",
    "        \"\"\"\n",
    "        return self.weights.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embedding matrix for a batch dimension of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0986, 0.9394, 0.7522, 0.0020, 0.7245],\n",
      "        [0.8452, 0.2748, 0.1371, 0.2975, 0.5863]])\n"
     ]
    }
   ],
   "source": [
    "batch_dim = 2\n",
    "num_classes = 3\n",
    "emb_size = 5\n",
    "embedding_matrix = torch.rand(batch_dim, emb_size)\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the corresponding ground truth label vector\n",
    "##### 3-class problem [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0],\n",
      "        [0, 0, 1]])\n",
      "tensor([1, 2])\n",
      "Shape of ground truth vector is torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ground_truth_vector = torch.tensor([1, 2])\n",
    "print(F.one_hot(ground_truth_vector))\n",
    "#ground_truth_vector = torch.tensor([[0, 1, 2]])\n",
    "print(ground_truth_vector)\n",
    "print(f\"Shape of ground truth vector is {ground_truth_vector.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch dim = 2\n",
      "Embedding size = 5\n",
      "Shape of embedding torch.Size([2, 5])\n",
      "No of classes = 3\n",
      "shape of weights torch.Size([3, 5])\n",
      "Shape of logits = torch.Size([2, 3])\n",
      "One hot encoded labels are tensor([[0, 1, 0],\n",
      "        [0, 0, 1]])\n",
      "Logits of all classes tensor([[ 0.1924,  0.6971,  0.3102],\n",
      "        [ 0.2836,  0.5013, -0.3012]], grad_fn=<MmBackward0>)\n",
      "original target logit = tensor([ 0.6971, -0.3012], grad_fn=<IndexBackward0>)\n",
      "diff in raw form is tensor([-0.4291, -0.4203], grad_fn=<SubBackward0>)\n",
      "diff after unsqueezing is tensor([[-0.4291],\n",
      "        [-0.4203]], grad_fn=<UnsqueezeBackward0>)\n",
      "fc7 originally is tensor([[ 0.1924,  0.6971,  0.3102],\n",
      "        [ 0.2836,  0.5013, -0.3012]], grad_fn=<MmBackward0>)\n",
      "Multiplication of one hot encoding with diff: tensor([[-0.0000, -0.4291, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.4203]], grad_fn=<MulBackward0>)\n",
      "fc7 after inclusion of margin in the ground truth logits \n",
      ": tensor([[ 0.1924,  0.2680,  0.3102],\n",
      "        [ 0.2836,  0.5013, -0.7215]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.3137,  17.1532,  19.8498],\n",
       "        [ 18.1530,  32.0855, -46.1732]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arcface_loss = ArcFace(emb_size, num_classes, s=64.0, m=0.50)\n",
    "arcface_loss.forward(embedding_matrix, ground_truth_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
